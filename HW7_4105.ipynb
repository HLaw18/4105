{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HLaw18/4105/blob/main/HW7_4105.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBZdvFl35ooS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELkg4cm33OQZ",
        "outputId": "9ed39383-4986-4946-fe4f-fd1e3d54f1a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 5s 0us/step\n",
            "Epoch 1/300\n",
            "1563/1563 [==============================] - 20s 6ms/step - loss: 1.4693 - accuracy: 0.4648 - val_loss: 1.1888 - val_accuracy: 0.5683\n",
            "Epoch 2/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1116 - accuracy: 0.6060 - val_loss: 1.0577 - val_accuracy: 0.6220\n",
            "Epoch 3/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9508 - accuracy: 0.6664 - val_loss: 0.9267 - val_accuracy: 0.6750\n",
            "Epoch 4/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8473 - accuracy: 0.7035 - val_loss: 0.8887 - val_accuracy: 0.6901\n",
            "Epoch 5/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7640 - accuracy: 0.7315 - val_loss: 0.8277 - val_accuracy: 0.7126\n",
            "Epoch 6/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7008 - accuracy: 0.7545 - val_loss: 0.8666 - val_accuracy: 0.7057\n",
            "Epoch 7/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6393 - accuracy: 0.7749 - val_loss: 0.8216 - val_accuracy: 0.7188\n",
            "Epoch 8/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5888 - accuracy: 0.7928 - val_loss: 0.8524 - val_accuracy: 0.7163\n",
            "Epoch 9/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5296 - accuracy: 0.8116 - val_loss: 0.8856 - val_accuracy: 0.7084\n",
            "Epoch 10/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4852 - accuracy: 0.8280 - val_loss: 0.8679 - val_accuracy: 0.7216\n",
            "Epoch 11/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4394 - accuracy: 0.8436 - val_loss: 0.9410 - val_accuracy: 0.7063\n",
            "Epoch 12/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3989 - accuracy: 0.8581 - val_loss: 0.9990 - val_accuracy: 0.7102\n",
            "Epoch 13/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3618 - accuracy: 0.8712 - val_loss: 1.0304 - val_accuracy: 0.7117\n",
            "Epoch 14/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3311 - accuracy: 0.8828 - val_loss: 1.1002 - val_accuracy: 0.7077\n",
            "Epoch 15/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2985 - accuracy: 0.8937 - val_loss: 1.1555 - val_accuracy: 0.7020\n",
            "Epoch 16/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2657 - accuracy: 0.9055 - val_loss: 1.2446 - val_accuracy: 0.7059\n",
            "Epoch 17/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2416 - accuracy: 0.9132 - val_loss: 1.2844 - val_accuracy: 0.6976\n",
            "Epoch 18/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2182 - accuracy: 0.9206 - val_loss: 1.3556 - val_accuracy: 0.7021\n",
            "Epoch 19/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1976 - accuracy: 0.9294 - val_loss: 1.5464 - val_accuracy: 0.6994\n",
            "Epoch 20/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1934 - accuracy: 0.9309 - val_loss: 1.5307 - val_accuracy: 0.6965\n",
            "Epoch 21/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1758 - accuracy: 0.9379 - val_loss: 1.5849 - val_accuracy: 0.6944\n",
            "Epoch 22/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1638 - accuracy: 0.9419 - val_loss: 1.6904 - val_accuracy: 0.6887\n",
            "Epoch 23/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1552 - accuracy: 0.9448 - val_loss: 1.7903 - val_accuracy: 0.6887\n",
            "Epoch 24/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1502 - accuracy: 0.9475 - val_loss: 1.7883 - val_accuracy: 0.6961\n",
            "Epoch 25/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1394 - accuracy: 0.9512 - val_loss: 1.9811 - val_accuracy: 0.6902\n",
            "Epoch 26/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1350 - accuracy: 0.9521 - val_loss: 2.1317 - val_accuracy: 0.6753\n",
            "Epoch 27/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1332 - accuracy: 0.9538 - val_loss: 2.0221 - val_accuracy: 0.6982\n",
            "Epoch 28/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1240 - accuracy: 0.9574 - val_loss: 2.1163 - val_accuracy: 0.6923\n",
            "Epoch 29/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1280 - accuracy: 0.9559 - val_loss: 2.1587 - val_accuracy: 0.6812\n",
            "Epoch 30/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1176 - accuracy: 0.9594 - val_loss: 2.2090 - val_accuracy: 0.6934\n",
            "Epoch 31/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1172 - accuracy: 0.9608 - val_loss: 2.3357 - val_accuracy: 0.6910\n",
            "Epoch 32/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1162 - accuracy: 0.9603 - val_loss: 2.3576 - val_accuracy: 0.6834\n",
            "Epoch 33/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1167 - accuracy: 0.9603 - val_loss: 2.2426 - val_accuracy: 0.6996\n",
            "Epoch 34/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1075 - accuracy: 0.9632 - val_loss: 2.3183 - val_accuracy: 0.6907\n",
            "Epoch 35/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0952 - accuracy: 0.9670 - val_loss: 2.3881 - val_accuracy: 0.6894\n",
            "Epoch 36/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1150 - accuracy: 0.9618 - val_loss: 2.4541 - val_accuracy: 0.6915\n",
            "Epoch 37/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1091 - accuracy: 0.9627 - val_loss: 2.5886 - val_accuracy: 0.6857\n",
            "Epoch 38/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1031 - accuracy: 0.9657 - val_loss: 2.6021 - val_accuracy: 0.6891\n",
            "Epoch 39/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0997 - accuracy: 0.9668 - val_loss: 2.5380 - val_accuracy: 0.6952\n",
            "Epoch 40/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0975 - accuracy: 0.9674 - val_loss: 2.6279 - val_accuracy: 0.6826\n",
            "Epoch 41/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0991 - accuracy: 0.9677 - val_loss: 2.6010 - val_accuracy: 0.6892\n",
            "Epoch 42/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1056 - accuracy: 0.9666 - val_loss: 2.5528 - val_accuracy: 0.6858\n",
            "Epoch 43/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0940 - accuracy: 0.9688 - val_loss: 2.6614 - val_accuracy: 0.6914\n",
            "Epoch 44/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0945 - accuracy: 0.9703 - val_loss: 2.8704 - val_accuracy: 0.6748\n",
            "Epoch 45/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0974 - accuracy: 0.9685 - val_loss: 2.7441 - val_accuracy: 0.6886\n",
            "Epoch 46/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0871 - accuracy: 0.9719 - val_loss: 2.7265 - val_accuracy: 0.6895\n",
            "Epoch 47/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1057 - accuracy: 0.9662 - val_loss: 2.8442 - val_accuracy: 0.6801\n",
            "Epoch 48/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0904 - accuracy: 0.9713 - val_loss: 2.9528 - val_accuracy: 0.6940\n",
            "Epoch 49/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0879 - accuracy: 0.9719 - val_loss: 2.8923 - val_accuracy: 0.6915\n",
            "Epoch 50/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0967 - accuracy: 0.9695 - val_loss: 3.0250 - val_accuracy: 0.6845\n",
            "Epoch 51/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0863 - accuracy: 0.9726 - val_loss: 2.9969 - val_accuracy: 0.6818\n",
            "Epoch 52/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0861 - accuracy: 0.9728 - val_loss: 3.0667 - val_accuracy: 0.6886\n",
            "Epoch 53/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0867 - accuracy: 0.9724 - val_loss: 2.9837 - val_accuracy: 0.6914\n",
            "Epoch 54/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0887 - accuracy: 0.9728 - val_loss: 3.1606 - val_accuracy: 0.6832\n",
            "Epoch 55/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0902 - accuracy: 0.9727 - val_loss: 3.1383 - val_accuracy: 0.6883\n",
            "Epoch 56/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0819 - accuracy: 0.9748 - val_loss: 3.3766 - val_accuracy: 0.6809\n",
            "Epoch 57/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0896 - accuracy: 0.9730 - val_loss: 3.2365 - val_accuracy: 0.6908\n",
            "Epoch 58/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0915 - accuracy: 0.9718 - val_loss: 3.2271 - val_accuracy: 0.6853\n",
            "Epoch 59/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0781 - accuracy: 0.9761 - val_loss: 3.3196 - val_accuracy: 0.6837\n",
            "Epoch 60/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0825 - accuracy: 0.9739 - val_loss: 3.3170 - val_accuracy: 0.6874\n",
            "Epoch 61/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0886 - accuracy: 0.9728 - val_loss: 3.2356 - val_accuracy: 0.6939\n",
            "Epoch 62/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0802 - accuracy: 0.9756 - val_loss: 3.4203 - val_accuracy: 0.6823\n",
            "Epoch 63/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0797 - accuracy: 0.9752 - val_loss: 3.3399 - val_accuracy: 0.6854\n",
            "Epoch 64/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0929 - accuracy: 0.9734 - val_loss: 3.4157 - val_accuracy: 0.6894\n",
            "Epoch 65/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0740 - accuracy: 0.9788 - val_loss: 3.3607 - val_accuracy: 0.6908\n",
            "Epoch 66/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0795 - accuracy: 0.9751 - val_loss: 3.5463 - val_accuracy: 0.6876\n",
            "Epoch 67/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0846 - accuracy: 0.9753 - val_loss: 3.5733 - val_accuracy: 0.6900\n",
            "Epoch 68/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0783 - accuracy: 0.9777 - val_loss: 3.5261 - val_accuracy: 0.6862\n",
            "Epoch 69/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0850 - accuracy: 0.9751 - val_loss: 3.5099 - val_accuracy: 0.6885\n",
            "Epoch 70/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0766 - accuracy: 0.9780 - val_loss: 3.6651 - val_accuracy: 0.6841\n",
            "Epoch 71/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0787 - accuracy: 0.9770 - val_loss: 3.5053 - val_accuracy: 0.6829\n",
            "Epoch 72/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0818 - accuracy: 0.9765 - val_loss: 3.5610 - val_accuracy: 0.6873\n",
            "Epoch 73/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0773 - accuracy: 0.9778 - val_loss: 3.6075 - val_accuracy: 0.6869\n",
            "Epoch 74/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0800 - accuracy: 0.9773 - val_loss: 3.5340 - val_accuracy: 0.6920\n",
            "Epoch 75/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0838 - accuracy: 0.9766 - val_loss: 3.5773 - val_accuracy: 0.6834\n",
            "Epoch 76/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0735 - accuracy: 0.9790 - val_loss: 3.7339 - val_accuracy: 0.6807\n",
            "Epoch 77/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0838 - accuracy: 0.9757 - val_loss: 3.7031 - val_accuracy: 0.6837\n",
            "Epoch 78/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0755 - accuracy: 0.9778 - val_loss: 3.5276 - val_accuracy: 0.6885\n",
            "Epoch 79/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0782 - accuracy: 0.9772 - val_loss: 3.7737 - val_accuracy: 0.6838\n",
            "Epoch 80/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0801 - accuracy: 0.9778 - val_loss: 3.8594 - val_accuracy: 0.6776\n",
            "Epoch 81/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0789 - accuracy: 0.9777 - val_loss: 3.9062 - val_accuracy: 0.6739\n",
            "Epoch 82/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0750 - accuracy: 0.9790 - val_loss: 3.6911 - val_accuracy: 0.6814\n",
            "Epoch 83/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0813 - accuracy: 0.9779 - val_loss: 3.7808 - val_accuracy: 0.6940\n",
            "Epoch 84/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0735 - accuracy: 0.9792 - val_loss: 3.8727 - val_accuracy: 0.6866\n",
            "Epoch 85/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0772 - accuracy: 0.9775 - val_loss: 3.7885 - val_accuracy: 0.6897\n",
            "Epoch 86/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0715 - accuracy: 0.9799 - val_loss: 3.8645 - val_accuracy: 0.6904\n",
            "Epoch 87/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0780 - accuracy: 0.9790 - val_loss: 4.1203 - val_accuracy: 0.6786\n",
            "Epoch 88/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0873 - accuracy: 0.9762 - val_loss: 4.0038 - val_accuracy: 0.6888\n",
            "Epoch 89/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0651 - accuracy: 0.9802 - val_loss: 3.9309 - val_accuracy: 0.6871\n",
            "Epoch 90/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0731 - accuracy: 0.9795 - val_loss: 4.0690 - val_accuracy: 0.6819\n",
            "Epoch 91/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0742 - accuracy: 0.9792 - val_loss: 4.0537 - val_accuracy: 0.6821\n",
            "Epoch 92/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0765 - accuracy: 0.9788 - val_loss: 4.0863 - val_accuracy: 0.6852\n",
            "Epoch 93/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0802 - accuracy: 0.9786 - val_loss: 4.2332 - val_accuracy: 0.6833\n",
            "Epoch 94/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0675 - accuracy: 0.9817 - val_loss: 4.1188 - val_accuracy: 0.6814\n",
            "Epoch 95/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0782 - accuracy: 0.9786 - val_loss: 4.1743 - val_accuracy: 0.6813\n",
            "Epoch 96/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0707 - accuracy: 0.9812 - val_loss: 4.3576 - val_accuracy: 0.6823\n",
            "Epoch 97/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0727 - accuracy: 0.9793 - val_loss: 4.1486 - val_accuracy: 0.6873\n",
            "Epoch 98/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0763 - accuracy: 0.9803 - val_loss: 4.2128 - val_accuracy: 0.6891\n",
            "Epoch 99/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0723 - accuracy: 0.9812 - val_loss: 4.3424 - val_accuracy: 0.6787\n",
            "Epoch 100/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0829 - accuracy: 0.9780 - val_loss: 4.3292 - val_accuracy: 0.6853\n",
            "Epoch 101/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0730 - accuracy: 0.9802 - val_loss: 4.4189 - val_accuracy: 0.6857\n",
            "Epoch 102/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0749 - accuracy: 0.9797 - val_loss: 4.4011 - val_accuracy: 0.6825\n",
            "Epoch 103/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0808 - accuracy: 0.9787 - val_loss: 4.4034 - val_accuracy: 0.6878\n",
            "Epoch 104/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0760 - accuracy: 0.9809 - val_loss: 4.3541 - val_accuracy: 0.6815\n",
            "Epoch 105/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0726 - accuracy: 0.9812 - val_loss: 4.4244 - val_accuracy: 0.6858\n",
            "Epoch 106/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0779 - accuracy: 0.9813 - val_loss: 4.3371 - val_accuracy: 0.6743\n",
            "Epoch 107/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0736 - accuracy: 0.9815 - val_loss: 4.5472 - val_accuracy: 0.6779\n",
            "Epoch 108/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0717 - accuracy: 0.9812 - val_loss: 4.6218 - val_accuracy: 0.6815\n",
            "Epoch 109/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0816 - accuracy: 0.9797 - val_loss: 4.4142 - val_accuracy: 0.6873\n",
            "Epoch 110/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0667 - accuracy: 0.9828 - val_loss: 4.5777 - val_accuracy: 0.6803\n",
            "Epoch 111/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0680 - accuracy: 0.9825 - val_loss: 4.5876 - val_accuracy: 0.6852\n",
            "Epoch 112/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0782 - accuracy: 0.9806 - val_loss: 4.8475 - val_accuracy: 0.6780\n",
            "Epoch 113/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0719 - accuracy: 0.9817 - val_loss: 4.6226 - val_accuracy: 0.6767\n",
            "Epoch 114/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0701 - accuracy: 0.9819 - val_loss: 4.6098 - val_accuracy: 0.6791\n",
            "Epoch 115/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0690 - accuracy: 0.9826 - val_loss: 4.7305 - val_accuracy: 0.6751\n",
            "Epoch 116/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0733 - accuracy: 0.9821 - val_loss: 4.8977 - val_accuracy: 0.6810\n",
            "Epoch 117/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0752 - accuracy: 0.9803 - val_loss: 4.7351 - val_accuracy: 0.6812\n",
            "Epoch 118/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0687 - accuracy: 0.9835 - val_loss: 4.8968 - val_accuracy: 0.6830\n",
            "Epoch 119/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0769 - accuracy: 0.9805 - val_loss: 4.7586 - val_accuracy: 0.6777\n",
            "Epoch 120/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0795 - accuracy: 0.9809 - val_loss: 4.8261 - val_accuracy: 0.6830\n",
            "Epoch 121/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0624 - accuracy: 0.9840 - val_loss: 5.0212 - val_accuracy: 0.6808\n",
            "Epoch 122/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0803 - accuracy: 0.9806 - val_loss: 5.1053 - val_accuracy: 0.6792\n",
            "Epoch 123/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0766 - accuracy: 0.9811 - val_loss: 5.1783 - val_accuracy: 0.6695\n",
            "Epoch 124/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0728 - accuracy: 0.9822 - val_loss: 4.8742 - val_accuracy: 0.6836\n",
            "Epoch 125/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0717 - accuracy: 0.9821 - val_loss: 5.1002 - val_accuracy: 0.6867\n",
            "Epoch 126/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0668 - accuracy: 0.9839 - val_loss: 5.1946 - val_accuracy: 0.6824\n",
            "Epoch 127/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0726 - accuracy: 0.9823 - val_loss: 5.5219 - val_accuracy: 0.6739\n",
            "Epoch 128/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0750 - accuracy: 0.9816 - val_loss: 5.1974 - val_accuracy: 0.6805\n",
            "Epoch 129/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0660 - accuracy: 0.9832 - val_loss: 5.3348 - val_accuracy: 0.6880\n",
            "Epoch 130/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0796 - accuracy: 0.9811 - val_loss: 5.1316 - val_accuracy: 0.6816\n",
            "Epoch 131/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0701 - accuracy: 0.9835 - val_loss: 5.0826 - val_accuracy: 0.6795\n",
            "Epoch 132/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0689 - accuracy: 0.9837 - val_loss: 5.5204 - val_accuracy: 0.6827\n",
            "Epoch 133/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0749 - accuracy: 0.9827 - val_loss: 5.0760 - val_accuracy: 0.6884\n",
            "Epoch 134/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0763 - accuracy: 0.9831 - val_loss: 5.5581 - val_accuracy: 0.6789\n",
            "Epoch 135/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0691 - accuracy: 0.9829 - val_loss: 5.3771 - val_accuracy: 0.6840\n",
            "Epoch 136/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0738 - accuracy: 0.9825 - val_loss: 5.4329 - val_accuracy: 0.6819\n",
            "Epoch 137/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0735 - accuracy: 0.9833 - val_loss: 5.6584 - val_accuracy: 0.6833\n",
            "Epoch 138/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0812 - accuracy: 0.9816 - val_loss: 5.6535 - val_accuracy: 0.6776\n",
            "Epoch 139/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0707 - accuracy: 0.9841 - val_loss: 5.4421 - val_accuracy: 0.6888\n",
            "Epoch 140/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0766 - accuracy: 0.9821 - val_loss: 5.7769 - val_accuracy: 0.6781\n",
            "Epoch 141/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0752 - accuracy: 0.9841 - val_loss: 5.8488 - val_accuracy: 0.6836\n",
            "Epoch 142/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0771 - accuracy: 0.9833 - val_loss: 5.8311 - val_accuracy: 0.6832\n",
            "Epoch 143/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0707 - accuracy: 0.9835 - val_loss: 5.6523 - val_accuracy: 0.6868\n",
            "Epoch 144/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0835 - accuracy: 0.9817 - val_loss: 5.7543 - val_accuracy: 0.6759\n",
            "Epoch 145/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0723 - accuracy: 0.9835 - val_loss: 5.5861 - val_accuracy: 0.6848\n",
            "Epoch 146/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0653 - accuracy: 0.9849 - val_loss: 5.7956 - val_accuracy: 0.6868\n",
            "Epoch 147/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0785 - accuracy: 0.9831 - val_loss: 5.8755 - val_accuracy: 0.6816\n",
            "Epoch 148/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0844 - accuracy: 0.9822 - val_loss: 5.7327 - val_accuracy: 0.6850\n",
            "Epoch 149/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0682 - accuracy: 0.9845 - val_loss: 5.7963 - val_accuracy: 0.6787\n",
            "Epoch 150/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0653 - accuracy: 0.9847 - val_loss: 6.1829 - val_accuracy: 0.6856\n",
            "Epoch 151/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0724 - accuracy: 0.9842 - val_loss: 6.0255 - val_accuracy: 0.6898\n",
            "Epoch 152/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0841 - accuracy: 0.9820 - val_loss: 6.5119 - val_accuracy: 0.6797\n",
            "Epoch 153/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0732 - accuracy: 0.9849 - val_loss: 6.3466 - val_accuracy: 0.6806\n",
            "Epoch 154/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0743 - accuracy: 0.9839 - val_loss: 6.4415 - val_accuracy: 0.6711\n",
            "Epoch 155/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0777 - accuracy: 0.9835 - val_loss: 6.0699 - val_accuracy: 0.6834\n",
            "Epoch 156/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0725 - accuracy: 0.9849 - val_loss: 6.4401 - val_accuracy: 0.6820\n",
            "Epoch 157/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0736 - accuracy: 0.9843 - val_loss: 6.2501 - val_accuracy: 0.6813\n",
            "Epoch 158/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0775 - accuracy: 0.9836 - val_loss: 6.2112 - val_accuracy: 0.6870\n",
            "Epoch 159/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0683 - accuracy: 0.9849 - val_loss: 6.4720 - val_accuracy: 0.6809\n",
            "Epoch 160/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0816 - accuracy: 0.9832 - val_loss: 6.8843 - val_accuracy: 0.6734\n",
            "Epoch 161/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0744 - accuracy: 0.9850 - val_loss: 6.5586 - val_accuracy: 0.6816\n",
            "Epoch 162/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0796 - accuracy: 0.9837 - val_loss: 6.4948 - val_accuracy: 0.6856\n",
            "Epoch 163/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0738 - accuracy: 0.9845 - val_loss: 6.9027 - val_accuracy: 0.6833\n",
            "Epoch 164/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0735 - accuracy: 0.9852 - val_loss: 6.4244 - val_accuracy: 0.6912\n",
            "Epoch 165/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0769 - accuracy: 0.9836 - val_loss: 6.8034 - val_accuracy: 0.6819\n",
            "Epoch 166/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0833 - accuracy: 0.9838 - val_loss: 6.7392 - val_accuracy: 0.6788\n",
            "Epoch 167/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0740 - accuracy: 0.9858 - val_loss: 6.8497 - val_accuracy: 0.6795\n",
            "Epoch 168/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0786 - accuracy: 0.9842 - val_loss: 6.8587 - val_accuracy: 0.6820\n",
            "Epoch 169/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0817 - accuracy: 0.9841 - val_loss: 6.6117 - val_accuracy: 0.6842\n",
            "Epoch 170/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0770 - accuracy: 0.9844 - val_loss: 7.0358 - val_accuracy: 0.6798\n",
            "Epoch 171/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0788 - accuracy: 0.9849 - val_loss: 7.2618 - val_accuracy: 0.6843\n",
            "Epoch 172/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0886 - accuracy: 0.9837 - val_loss: 7.4326 - val_accuracy: 0.6719\n",
            "Epoch 173/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0780 - accuracy: 0.9852 - val_loss: 7.4502 - val_accuracy: 0.6700\n",
            "Epoch 174/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0799 - accuracy: 0.9840 - val_loss: 7.3067 - val_accuracy: 0.6776\n",
            "Epoch 175/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0788 - accuracy: 0.9848 - val_loss: 7.0958 - val_accuracy: 0.6823\n",
            "Epoch 176/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0815 - accuracy: 0.9844 - val_loss: 7.4149 - val_accuracy: 0.6792\n",
            "Epoch 177/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0916 - accuracy: 0.9840 - val_loss: 7.1706 - val_accuracy: 0.6824\n",
            "Epoch 178/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0742 - accuracy: 0.9858 - val_loss: 7.4835 - val_accuracy: 0.6812\n",
            "Epoch 179/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0916 - accuracy: 0.9831 - val_loss: 7.3365 - val_accuracy: 0.6800\n",
            "Epoch 180/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0809 - accuracy: 0.9846 - val_loss: 7.4553 - val_accuracy: 0.6879\n",
            "Epoch 181/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0851 - accuracy: 0.9849 - val_loss: 7.4867 - val_accuracy: 0.6816\n",
            "Epoch 182/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0759 - accuracy: 0.9864 - val_loss: 7.6232 - val_accuracy: 0.6780\n",
            "Epoch 183/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0838 - accuracy: 0.9841 - val_loss: 7.5074 - val_accuracy: 0.6758\n",
            "Epoch 184/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0839 - accuracy: 0.9851 - val_loss: 7.7240 - val_accuracy: 0.6747\n",
            "Epoch 185/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0842 - accuracy: 0.9844 - val_loss: 7.5960 - val_accuracy: 0.6828\n",
            "Epoch 186/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0751 - accuracy: 0.9850 - val_loss: 7.9259 - val_accuracy: 0.6728\n",
            "Epoch 187/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0794 - accuracy: 0.9853 - val_loss: 7.5806 - val_accuracy: 0.6819\n",
            "Epoch 188/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0713 - accuracy: 0.9862 - val_loss: 7.6300 - val_accuracy: 0.6797\n",
            "Epoch 189/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0805 - accuracy: 0.9852 - val_loss: 7.5995 - val_accuracy: 0.6756\n",
            "Epoch 190/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0770 - accuracy: 0.9865 - val_loss: 7.9351 - val_accuracy: 0.6753\n",
            "Epoch 191/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0754 - accuracy: 0.9859 - val_loss: 7.7078 - val_accuracy: 0.6812\n",
            "Epoch 192/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1016 - accuracy: 0.9830 - val_loss: 7.8479 - val_accuracy: 0.6800\n",
            "Epoch 193/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0857 - accuracy: 0.9851 - val_loss: 8.1124 - val_accuracy: 0.6756\n",
            "Epoch 194/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0713 - accuracy: 0.9870 - val_loss: 7.9443 - val_accuracy: 0.6732\n",
            "Epoch 195/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0889 - accuracy: 0.9843 - val_loss: 8.3413 - val_accuracy: 0.6711\n",
            "Epoch 196/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0759 - accuracy: 0.9865 - val_loss: 8.0137 - val_accuracy: 0.6759\n",
            "Epoch 197/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0860 - accuracy: 0.9855 - val_loss: 8.0847 - val_accuracy: 0.6823\n",
            "Epoch 198/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0796 - accuracy: 0.9856 - val_loss: 7.8516 - val_accuracy: 0.6712\n",
            "Epoch 199/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0855 - accuracy: 0.9845 - val_loss: 8.3870 - val_accuracy: 0.6752\n",
            "Epoch 200/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0874 - accuracy: 0.9851 - val_loss: 8.3717 - val_accuracy: 0.6777\n",
            "Epoch 201/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0758 - accuracy: 0.9864 - val_loss: 8.3534 - val_accuracy: 0.6789\n",
            "Epoch 202/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0791 - accuracy: 0.9854 - val_loss: 8.5983 - val_accuracy: 0.6824\n",
            "Epoch 203/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0846 - accuracy: 0.9858 - val_loss: 9.2572 - val_accuracy: 0.6654\n",
            "Epoch 204/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0818 - accuracy: 0.9858 - val_loss: 8.6887 - val_accuracy: 0.6743\n",
            "Epoch 205/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0828 - accuracy: 0.9855 - val_loss: 8.8131 - val_accuracy: 0.6678\n",
            "Epoch 206/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0911 - accuracy: 0.9850 - val_loss: 8.6193 - val_accuracy: 0.6801\n",
            "Epoch 207/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0878 - accuracy: 0.9850 - val_loss: 8.6752 - val_accuracy: 0.6775\n",
            "Epoch 208/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0821 - accuracy: 0.9861 - val_loss: 8.8216 - val_accuracy: 0.6783\n",
            "Epoch 209/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0754 - accuracy: 0.9868 - val_loss: 8.8942 - val_accuracy: 0.6803\n",
            "Epoch 210/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0809 - accuracy: 0.9865 - val_loss: 8.8730 - val_accuracy: 0.6777\n",
            "Epoch 211/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1009 - accuracy: 0.9834 - val_loss: 9.0981 - val_accuracy: 0.6666\n",
            "Epoch 212/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0746 - accuracy: 0.9871 - val_loss: 8.9164 - val_accuracy: 0.6819\n",
            "Epoch 213/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0931 - accuracy: 0.9855 - val_loss: 9.4040 - val_accuracy: 0.6705\n",
            "Epoch 214/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0799 - accuracy: 0.9861 - val_loss: 9.3826 - val_accuracy: 0.6776\n",
            "Epoch 215/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0892 - accuracy: 0.9862 - val_loss: 9.3091 - val_accuracy: 0.6744\n",
            "Epoch 216/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0864 - accuracy: 0.9865 - val_loss: 9.3419 - val_accuracy: 0.6799\n",
            "Epoch 217/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0892 - accuracy: 0.9859 - val_loss: 9.1414 - val_accuracy: 0.6761\n",
            "Epoch 218/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1007 - accuracy: 0.9846 - val_loss: 9.1722 - val_accuracy: 0.6692\n",
            "Epoch 219/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0883 - accuracy: 0.9860 - val_loss: 9.2751 - val_accuracy: 0.6771\n",
            "Epoch 220/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0854 - accuracy: 0.9869 - val_loss: 9.2690 - val_accuracy: 0.6799\n",
            "Epoch 221/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0885 - accuracy: 0.9861 - val_loss: 9.4047 - val_accuracy: 0.6800\n",
            "Epoch 222/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0891 - accuracy: 0.9862 - val_loss: 9.0756 - val_accuracy: 0.6781\n",
            "Epoch 223/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0873 - accuracy: 0.9861 - val_loss: 9.5311 - val_accuracy: 0.6803\n",
            "Epoch 224/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0960 - accuracy: 0.9857 - val_loss: 9.4462 - val_accuracy: 0.6824\n",
            "Epoch 225/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1114 - accuracy: 0.9839 - val_loss: 9.2506 - val_accuracy: 0.6803\n",
            "Epoch 226/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0794 - accuracy: 0.9878 - val_loss: 9.5872 - val_accuracy: 0.6793\n",
            "Epoch 227/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0859 - accuracy: 0.9862 - val_loss: 10.1247 - val_accuracy: 0.6767\n",
            "Epoch 228/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0917 - accuracy: 0.9870 - val_loss: 9.9939 - val_accuracy: 0.6748\n",
            "Epoch 229/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0974 - accuracy: 0.9857 - val_loss: 9.6007 - val_accuracy: 0.6784\n",
            "Epoch 230/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0768 - accuracy: 0.9878 - val_loss: 9.7410 - val_accuracy: 0.6794\n",
            "Epoch 231/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0883 - accuracy: 0.9862 - val_loss: 9.7653 - val_accuracy: 0.6827\n",
            "Epoch 232/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0866 - accuracy: 0.9868 - val_loss: 10.2582 - val_accuracy: 0.6705\n",
            "Epoch 233/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0848 - accuracy: 0.9871 - val_loss: 9.9111 - val_accuracy: 0.6751\n",
            "Epoch 234/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0947 - accuracy: 0.9861 - val_loss: 9.9823 - val_accuracy: 0.6681\n",
            "Epoch 235/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1006 - accuracy: 0.9851 - val_loss: 10.3204 - val_accuracy: 0.6691\n",
            "Epoch 236/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0877 - accuracy: 0.9874 - val_loss: 10.1573 - val_accuracy: 0.6795\n",
            "Epoch 237/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0802 - accuracy: 0.9878 - val_loss: 10.2525 - val_accuracy: 0.6793\n",
            "Epoch 238/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1024 - accuracy: 0.9853 - val_loss: 10.2854 - val_accuracy: 0.6748\n",
            "Epoch 239/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0925 - accuracy: 0.9871 - val_loss: 10.1835 - val_accuracy: 0.6809\n",
            "Epoch 240/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0841 - accuracy: 0.9873 - val_loss: 10.8054 - val_accuracy: 0.6742\n",
            "Epoch 241/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0975 - accuracy: 0.9860 - val_loss: 10.5114 - val_accuracy: 0.6667\n",
            "Epoch 242/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0794 - accuracy: 0.9888 - val_loss: 10.6049 - val_accuracy: 0.6723\n",
            "Epoch 243/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1070 - accuracy: 0.9847 - val_loss: 10.1298 - val_accuracy: 0.6780\n",
            "Epoch 244/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0860 - accuracy: 0.9875 - val_loss: 10.4852 - val_accuracy: 0.6756\n",
            "Epoch 245/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0797 - accuracy: 0.9878 - val_loss: 10.9658 - val_accuracy: 0.6792\n",
            "Epoch 246/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1080 - accuracy: 0.9863 - val_loss: 10.6864 - val_accuracy: 0.6801\n",
            "Epoch 247/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0830 - accuracy: 0.9879 - val_loss: 11.5484 - val_accuracy: 0.6750\n",
            "Epoch 248/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1139 - accuracy: 0.9853 - val_loss: 10.8128 - val_accuracy: 0.6726\n",
            "Epoch 249/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0743 - accuracy: 0.9887 - val_loss: 10.7787 - val_accuracy: 0.6813\n",
            "Epoch 250/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0934 - accuracy: 0.9867 - val_loss: 11.2239 - val_accuracy: 0.6643\n",
            "Epoch 251/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1006 - accuracy: 0.9860 - val_loss: 11.2020 - val_accuracy: 0.6782\n",
            "Epoch 252/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0874 - accuracy: 0.9876 - val_loss: 10.8318 - val_accuracy: 0.6779\n",
            "Epoch 253/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0938 - accuracy: 0.9871 - val_loss: 11.0340 - val_accuracy: 0.6789\n",
            "Epoch 254/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1040 - accuracy: 0.9852 - val_loss: 10.9599 - val_accuracy: 0.6765\n",
            "Epoch 255/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1043 - accuracy: 0.9869 - val_loss: 11.1683 - val_accuracy: 0.6809\n",
            "Epoch 256/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0946 - accuracy: 0.9869 - val_loss: 11.0335 - val_accuracy: 0.6759\n",
            "Epoch 257/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1026 - accuracy: 0.9869 - val_loss: 11.8878 - val_accuracy: 0.6697\n",
            "Epoch 258/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0916 - accuracy: 0.9874 - val_loss: 11.2414 - val_accuracy: 0.6867\n",
            "Epoch 259/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0911 - accuracy: 0.9871 - val_loss: 11.8481 - val_accuracy: 0.6691\n",
            "Epoch 260/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0904 - accuracy: 0.9881 - val_loss: 12.0694 - val_accuracy: 0.6790\n",
            "Epoch 261/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1056 - accuracy: 0.9872 - val_loss: 11.6561 - val_accuracy: 0.6764\n",
            "Epoch 262/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1026 - accuracy: 0.9869 - val_loss: 11.5741 - val_accuracy: 0.6791\n",
            "Epoch 263/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0877 - accuracy: 0.9881 - val_loss: 12.0706 - val_accuracy: 0.6819\n",
            "Epoch 264/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1198 - accuracy: 0.9856 - val_loss: 12.0752 - val_accuracy: 0.6803\n",
            "Epoch 265/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0996 - accuracy: 0.9879 - val_loss: 11.9751 - val_accuracy: 0.6740\n",
            "Epoch 266/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0986 - accuracy: 0.9872 - val_loss: 11.9122 - val_accuracy: 0.6800\n",
            "Epoch 267/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0845 - accuracy: 0.9886 - val_loss: 12.2444 - val_accuracy: 0.6726\n",
            "Epoch 268/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0983 - accuracy: 0.9873 - val_loss: 12.1607 - val_accuracy: 0.6828\n",
            "Epoch 269/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1010 - accuracy: 0.9874 - val_loss: 12.2947 - val_accuracy: 0.6796\n",
            "Epoch 270/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1047 - accuracy: 0.9877 - val_loss: 12.7280 - val_accuracy: 0.6810\n",
            "Epoch 271/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1010 - accuracy: 0.9878 - val_loss: 12.0933 - val_accuracy: 0.6760\n",
            "Epoch 272/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0924 - accuracy: 0.9880 - val_loss: 12.1626 - val_accuracy: 0.6751\n",
            "Epoch 273/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0917 - accuracy: 0.9883 - val_loss: 12.0213 - val_accuracy: 0.6824\n",
            "Epoch 274/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1068 - accuracy: 0.9867 - val_loss: 12.6873 - val_accuracy: 0.6749\n",
            "Epoch 275/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0928 - accuracy: 0.9887 - val_loss: 13.1149 - val_accuracy: 0.6659\n",
            "Epoch 276/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1034 - accuracy: 0.9873 - val_loss: 12.4535 - val_accuracy: 0.6780\n",
            "Epoch 277/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0843 - accuracy: 0.9888 - val_loss: 13.0253 - val_accuracy: 0.6731\n",
            "Epoch 278/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1085 - accuracy: 0.9877 - val_loss: 12.8972 - val_accuracy: 0.6814\n",
            "Epoch 279/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0955 - accuracy: 0.9888 - val_loss: 13.0946 - val_accuracy: 0.6764\n",
            "Epoch 280/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1098 - accuracy: 0.9867 - val_loss: 13.6221 - val_accuracy: 0.6751\n",
            "Epoch 281/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1064 - accuracy: 0.9874 - val_loss: 13.7980 - val_accuracy: 0.6709\n",
            "Epoch 282/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0983 - accuracy: 0.9885 - val_loss: 13.4775 - val_accuracy: 0.6766\n",
            "Epoch 283/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0897 - accuracy: 0.9888 - val_loss: 13.3562 - val_accuracy: 0.6761\n",
            "Epoch 284/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1148 - accuracy: 0.9875 - val_loss: 13.2493 - val_accuracy: 0.6726\n",
            "Epoch 285/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1143 - accuracy: 0.9874 - val_loss: 13.4672 - val_accuracy: 0.6823\n",
            "Epoch 286/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1043 - accuracy: 0.9879 - val_loss: 13.9576 - val_accuracy: 0.6768\n",
            "Epoch 287/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1133 - accuracy: 0.9873 - val_loss: 13.6600 - val_accuracy: 0.6805\n",
            "Epoch 288/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1079 - accuracy: 0.9872 - val_loss: 13.8733 - val_accuracy: 0.6757\n",
            "Epoch 289/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0999 - accuracy: 0.9879 - val_loss: 14.8532 - val_accuracy: 0.6678\n",
            "Epoch 290/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0986 - accuracy: 0.9888 - val_loss: 13.9334 - val_accuracy: 0.6779\n",
            "Epoch 291/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0997 - accuracy: 0.9883 - val_loss: 13.7956 - val_accuracy: 0.6808\n",
            "Epoch 292/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1017 - accuracy: 0.9879 - val_loss: 14.0380 - val_accuracy: 0.6796\n",
            "Epoch 293/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1291 - accuracy: 0.9871 - val_loss: 14.0474 - val_accuracy: 0.6768\n",
            "Epoch 294/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1001 - accuracy: 0.9889 - val_loss: 13.9764 - val_accuracy: 0.6717\n",
            "Epoch 295/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0951 - accuracy: 0.9888 - val_loss: 13.9428 - val_accuracy: 0.6844\n",
            "Epoch 296/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1016 - accuracy: 0.9882 - val_loss: 14.1574 - val_accuracy: 0.6787\n",
            "Epoch 297/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1052 - accuracy: 0.9877 - val_loss: 14.0949 - val_accuracy: 0.6750\n",
            "Epoch 298/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1073 - accuracy: 0.9884 - val_loss: 14.6636 - val_accuracy: 0.6702\n",
            "Epoch 299/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1154 - accuracy: 0.9879 - val_loss: 14.3054 - val_accuracy: 0.6791\n",
            "Epoch 300/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1045 - accuracy: 0.9885 - val_loss: 14.2786 - val_accuracy: 0.6762\n",
            "Training Time: 2725.087307214737 seconds\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 14.2786 - accuracy: 0.6762\n",
            "Training Loss: 0.10449422895908356\n",
            "Evaluation Accuracy: 0.6761999726295471\n"
          ]
        }
      ],
      "source": [
        "#1a\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "history = model.fit(train_images, train_labels, epochs=300, validation_data=(test_images, test_labels))\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Training Time: {end_time - start_time} seconds\")\n",
        "training_loss = history.history['loss'][-1]\n",
        "evaluation_accuracy = model.evaluate(test_images, test_labels)[1]\n",
        "print(f\"Training Loss: {training_loss}\")\n",
        "print(f\"Evaluation Accuracy: {evaluation_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qepaTcFz3VXF",
        "outputId": "0f0ae6d7-c402-4bdf-b697-8924bfc68c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.4998 - accuracy: 0.4525 - val_loss: 1.3122 - val_accuracy: 0.5329\n",
            "Epoch 2/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1208 - accuracy: 0.6047 - val_loss: 1.0437 - val_accuracy: 0.6308\n",
            "Epoch 3/300\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9555 - accuracy: 0.6629 - val_loss: 1.0140 - val_accuracy: 0.6447\n",
            "Epoch 4/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8456 - accuracy: 0.7027 - val_loss: 0.9392 - val_accuracy: 0.6798\n",
            "Epoch 5/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7581 - accuracy: 0.7341 - val_loss: 0.8808 - val_accuracy: 0.7050\n",
            "Epoch 6/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6888 - accuracy: 0.7578 - val_loss: 0.8410 - val_accuracy: 0.7142\n",
            "Epoch 7/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6213 - accuracy: 0.7830 - val_loss: 0.8417 - val_accuracy: 0.7146\n",
            "Epoch 8/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5684 - accuracy: 0.8005 - val_loss: 0.8606 - val_accuracy: 0.7151\n",
            "Epoch 9/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5216 - accuracy: 0.8175 - val_loss: 0.8796 - val_accuracy: 0.7152\n",
            "Epoch 10/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4655 - accuracy: 0.8351 - val_loss: 0.9059 - val_accuracy: 0.7190\n",
            "Epoch 11/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4253 - accuracy: 0.8499 - val_loss: 0.9565 - val_accuracy: 0.7140\n",
            "Epoch 12/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3808 - accuracy: 0.8655 - val_loss: 0.9781 - val_accuracy: 0.7175\n",
            "Epoch 13/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3466 - accuracy: 0.8749 - val_loss: 1.0169 - val_accuracy: 0.7142\n",
            "Epoch 14/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3124 - accuracy: 0.8884 - val_loss: 1.0475 - val_accuracy: 0.7214\n",
            "Epoch 15/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2785 - accuracy: 0.9000 - val_loss: 1.1444 - val_accuracy: 0.7190\n",
            "Epoch 16/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2566 - accuracy: 0.9069 - val_loss: 1.2176 - val_accuracy: 0.7195\n",
            "Epoch 17/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2328 - accuracy: 0.9180 - val_loss: 1.2850 - val_accuracy: 0.7101\n",
            "Epoch 18/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2102 - accuracy: 0.9246 - val_loss: 1.3763 - val_accuracy: 0.7059\n",
            "Epoch 19/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1980 - accuracy: 0.9294 - val_loss: 1.4467 - val_accuracy: 0.7064\n",
            "Epoch 20/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1813 - accuracy: 0.9341 - val_loss: 1.5655 - val_accuracy: 0.7118\n",
            "Epoch 21/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1705 - accuracy: 0.9387 - val_loss: 1.6663 - val_accuracy: 0.6925\n",
            "Epoch 22/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1627 - accuracy: 0.9416 - val_loss: 1.5932 - val_accuracy: 0.7067\n",
            "Epoch 23/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1516 - accuracy: 0.9466 - val_loss: 1.6377 - val_accuracy: 0.7098\n",
            "Epoch 24/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1528 - accuracy: 0.9462 - val_loss: 1.6727 - val_accuracy: 0.7080\n",
            "Epoch 25/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1440 - accuracy: 0.9485 - val_loss: 1.7535 - val_accuracy: 0.7102\n",
            "Epoch 26/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1387 - accuracy: 0.9516 - val_loss: 1.8527 - val_accuracy: 0.7122\n",
            "Epoch 27/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1356 - accuracy: 0.9524 - val_loss: 1.9589 - val_accuracy: 0.6879\n",
            "Epoch 28/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1314 - accuracy: 0.9528 - val_loss: 1.9242 - val_accuracy: 0.7061\n",
            "Epoch 29/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1315 - accuracy: 0.9542 - val_loss: 1.9336 - val_accuracy: 0.7032\n",
            "Epoch 30/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1237 - accuracy: 0.9576 - val_loss: 2.0565 - val_accuracy: 0.7011\n",
            "Epoch 31/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1187 - accuracy: 0.9598 - val_loss: 2.1002 - val_accuracy: 0.7053\n",
            "Epoch 32/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1160 - accuracy: 0.9605 - val_loss: 2.0991 - val_accuracy: 0.6946\n",
            "Epoch 33/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1208 - accuracy: 0.9588 - val_loss: 2.1617 - val_accuracy: 0.7002\n",
            "Epoch 34/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1107 - accuracy: 0.9620 - val_loss: 2.2304 - val_accuracy: 0.7072\n",
            "Epoch 35/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1135 - accuracy: 0.9607 - val_loss: 2.2323 - val_accuracy: 0.7049\n",
            "Epoch 36/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1096 - accuracy: 0.9641 - val_loss: 2.4467 - val_accuracy: 0.6896\n",
            "Epoch 37/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1095 - accuracy: 0.9633 - val_loss: 2.3682 - val_accuracy: 0.6993\n",
            "Epoch 38/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1090 - accuracy: 0.9637 - val_loss: 2.3549 - val_accuracy: 0.6999\n",
            "Epoch 39/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1119 - accuracy: 0.9631 - val_loss: 2.3489 - val_accuracy: 0.7056\n",
            "Epoch 40/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1001 - accuracy: 0.9665 - val_loss: 2.3986 - val_accuracy: 0.6996\n",
            "Epoch 41/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1050 - accuracy: 0.9661 - val_loss: 2.5094 - val_accuracy: 0.7077\n",
            "Epoch 42/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1016 - accuracy: 0.9672 - val_loss: 2.5042 - val_accuracy: 0.6976\n",
            "Epoch 43/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1078 - accuracy: 0.9646 - val_loss: 2.5502 - val_accuracy: 0.7074\n",
            "Epoch 44/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1118 - accuracy: 0.9649 - val_loss: 2.5092 - val_accuracy: 0.7068\n",
            "Epoch 45/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0966 - accuracy: 0.9690 - val_loss: 2.5889 - val_accuracy: 0.7068\n",
            "Epoch 46/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0978 - accuracy: 0.9683 - val_loss: 2.7411 - val_accuracy: 0.6956\n",
            "Epoch 47/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1108 - accuracy: 0.9646 - val_loss: 2.6419 - val_accuracy: 0.7050\n",
            "Epoch 48/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0935 - accuracy: 0.9698 - val_loss: 2.6692 - val_accuracy: 0.7088\n",
            "Epoch 49/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0923 - accuracy: 0.9699 - val_loss: 2.7313 - val_accuracy: 0.7101\n",
            "Epoch 50/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1032 - accuracy: 0.9681 - val_loss: 2.7457 - val_accuracy: 0.7003\n",
            "Epoch 51/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0931 - accuracy: 0.9706 - val_loss: 2.8086 - val_accuracy: 0.7011\n",
            "Epoch 52/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1011 - accuracy: 0.9688 - val_loss: 2.6702 - val_accuracy: 0.7024\n",
            "Epoch 53/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0862 - accuracy: 0.9719 - val_loss: 2.8792 - val_accuracy: 0.7014\n",
            "Epoch 54/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0962 - accuracy: 0.9694 - val_loss: 2.7642 - val_accuracy: 0.7010\n",
            "Epoch 55/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0945 - accuracy: 0.9707 - val_loss: 2.8230 - val_accuracy: 0.6990\n",
            "Epoch 56/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0899 - accuracy: 0.9725 - val_loss: 2.8803 - val_accuracy: 0.7065\n",
            "Epoch 57/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0935 - accuracy: 0.9712 - val_loss: 2.9537 - val_accuracy: 0.7032\n",
            "Epoch 58/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0906 - accuracy: 0.9720 - val_loss: 2.8799 - val_accuracy: 0.7012\n",
            "Epoch 59/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0905 - accuracy: 0.9722 - val_loss: 2.9242 - val_accuracy: 0.7049\n",
            "Epoch 60/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0838 - accuracy: 0.9744 - val_loss: 3.0212 - val_accuracy: 0.7049\n",
            "Epoch 61/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0905 - accuracy: 0.9735 - val_loss: 3.0569 - val_accuracy: 0.6956\n",
            "Epoch 62/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0872 - accuracy: 0.9742 - val_loss: 3.2044 - val_accuracy: 0.7000\n",
            "Epoch 63/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0987 - accuracy: 0.9710 - val_loss: 3.0405 - val_accuracy: 0.7003\n",
            "Epoch 64/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0834 - accuracy: 0.9746 - val_loss: 3.0944 - val_accuracy: 0.7031\n",
            "Epoch 65/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0873 - accuracy: 0.9729 - val_loss: 3.2181 - val_accuracy: 0.7011\n",
            "Epoch 66/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0861 - accuracy: 0.9744 - val_loss: 3.1891 - val_accuracy: 0.6992\n",
            "Epoch 67/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0887 - accuracy: 0.9736 - val_loss: 3.2154 - val_accuracy: 0.7073\n",
            "Epoch 68/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0862 - accuracy: 0.9744 - val_loss: 3.1619 - val_accuracy: 0.6990\n",
            "Epoch 69/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0903 - accuracy: 0.9740 - val_loss: 3.3908 - val_accuracy: 0.6980\n",
            "Epoch 70/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0927 - accuracy: 0.9729 - val_loss: 3.3448 - val_accuracy: 0.6907\n",
            "Epoch 71/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0831 - accuracy: 0.9748 - val_loss: 3.2953 - val_accuracy: 0.7030\n",
            "Epoch 72/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0921 - accuracy: 0.9735 - val_loss: 3.4109 - val_accuracy: 0.6959\n",
            "Epoch 73/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0847 - accuracy: 0.9754 - val_loss: 3.2969 - val_accuracy: 0.6970\n",
            "Epoch 74/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0855 - accuracy: 0.9752 - val_loss: 3.4232 - val_accuracy: 0.6978\n",
            "Epoch 75/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0829 - accuracy: 0.9755 - val_loss: 3.5477 - val_accuracy: 0.6998\n",
            "Epoch 76/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0892 - accuracy: 0.9745 - val_loss: 3.2295 - val_accuracy: 0.7024\n",
            "Epoch 77/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0834 - accuracy: 0.9765 - val_loss: 3.6236 - val_accuracy: 0.6987\n",
            "Epoch 78/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0886 - accuracy: 0.9745 - val_loss: 3.4023 - val_accuracy: 0.7011\n",
            "Epoch 79/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0801 - accuracy: 0.9770 - val_loss: 3.5262 - val_accuracy: 0.6963\n",
            "Epoch 80/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0908 - accuracy: 0.9742 - val_loss: 3.5051 - val_accuracy: 0.7020\n",
            "Epoch 81/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0772 - accuracy: 0.9784 - val_loss: 3.5577 - val_accuracy: 0.7008\n",
            "Epoch 82/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0916 - accuracy: 0.9744 - val_loss: 3.4806 - val_accuracy: 0.6949\n",
            "Epoch 83/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0846 - accuracy: 0.9760 - val_loss: 3.6236 - val_accuracy: 0.6945\n",
            "Epoch 84/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0774 - accuracy: 0.9769 - val_loss: 3.8169 - val_accuracy: 0.6944\n",
            "Epoch 85/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0881 - accuracy: 0.9751 - val_loss: 3.5613 - val_accuracy: 0.7066\n",
            "Epoch 86/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0715 - accuracy: 0.9796 - val_loss: 3.7227 - val_accuracy: 0.7028\n",
            "Epoch 87/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0894 - accuracy: 0.9760 - val_loss: 3.7183 - val_accuracy: 0.6946\n",
            "Epoch 88/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0777 - accuracy: 0.9778 - val_loss: 3.7026 - val_accuracy: 0.7071\n",
            "Epoch 89/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0796 - accuracy: 0.9784 - val_loss: 3.6895 - val_accuracy: 0.7022\n",
            "Epoch 90/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0849 - accuracy: 0.9770 - val_loss: 3.7496 - val_accuracy: 0.6899\n",
            "Epoch 91/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0776 - accuracy: 0.9786 - val_loss: 3.7507 - val_accuracy: 0.6958\n",
            "Epoch 92/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0795 - accuracy: 0.9782 - val_loss: 3.8392 - val_accuracy: 0.7008\n",
            "Epoch 93/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0816 - accuracy: 0.9781 - val_loss: 3.9201 - val_accuracy: 0.6915\n",
            "Epoch 94/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0680 - accuracy: 0.9804 - val_loss: 3.9655 - val_accuracy: 0.6995\n",
            "Epoch 95/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0902 - accuracy: 0.9761 - val_loss: 3.8574 - val_accuracy: 0.7002\n",
            "Epoch 96/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0690 - accuracy: 0.9806 - val_loss: 3.9300 - val_accuracy: 0.6986\n",
            "Epoch 97/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0975 - accuracy: 0.9758 - val_loss: 3.9581 - val_accuracy: 0.7005\n",
            "Epoch 98/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0745 - accuracy: 0.9795 - val_loss: 4.1435 - val_accuracy: 0.6920\n",
            "Epoch 99/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0849 - accuracy: 0.9786 - val_loss: 4.1659 - val_accuracy: 0.6908\n",
            "Epoch 100/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0758 - accuracy: 0.9795 - val_loss: 4.0823 - val_accuracy: 0.6960\n",
            "Epoch 101/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0798 - accuracy: 0.9788 - val_loss: 4.0428 - val_accuracy: 0.6921\n",
            "Epoch 102/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0856 - accuracy: 0.9779 - val_loss: 4.0169 - val_accuracy: 0.6973\n",
            "Epoch 103/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0838 - accuracy: 0.9782 - val_loss: 4.1861 - val_accuracy: 0.6963\n",
            "Epoch 104/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0823 - accuracy: 0.9792 - val_loss: 4.3472 - val_accuracy: 0.6938\n",
            "Epoch 105/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0850 - accuracy: 0.9782 - val_loss: 4.3164 - val_accuracy: 0.6892\n",
            "Epoch 106/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0774 - accuracy: 0.9800 - val_loss: 4.2341 - val_accuracy: 0.6978\n",
            "Epoch 107/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0767 - accuracy: 0.9796 - val_loss: 4.3733 - val_accuracy: 0.6895\n",
            "Epoch 108/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0770 - accuracy: 0.9800 - val_loss: 4.2806 - val_accuracy: 0.6957\n",
            "Epoch 109/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0741 - accuracy: 0.9806 - val_loss: 4.2089 - val_accuracy: 0.6929\n",
            "Epoch 110/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0845 - accuracy: 0.9790 - val_loss: 4.5330 - val_accuracy: 0.6921\n",
            "Epoch 111/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0851 - accuracy: 0.9791 - val_loss: 4.4512 - val_accuracy: 0.6846\n",
            "Epoch 112/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0801 - accuracy: 0.9797 - val_loss: 4.1897 - val_accuracy: 0.6926\n",
            "Epoch 113/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0731 - accuracy: 0.9810 - val_loss: 4.6640 - val_accuracy: 0.6928\n",
            "Epoch 114/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0833 - accuracy: 0.9796 - val_loss: 4.5558 - val_accuracy: 0.6958\n",
            "Epoch 115/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0849 - accuracy: 0.9793 - val_loss: 4.4534 - val_accuracy: 0.6991\n",
            "Epoch 116/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0819 - accuracy: 0.9798 - val_loss: 4.5565 - val_accuracy: 0.6943\n",
            "Epoch 117/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0850 - accuracy: 0.9787 - val_loss: 4.4991 - val_accuracy: 0.6962\n",
            "Epoch 118/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0779 - accuracy: 0.9810 - val_loss: 4.6004 - val_accuracy: 0.6962\n",
            "Epoch 119/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0815 - accuracy: 0.9803 - val_loss: 4.7274 - val_accuracy: 0.6994\n",
            "Epoch 120/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0820 - accuracy: 0.9802 - val_loss: 4.3479 - val_accuracy: 0.6988\n",
            "Epoch 121/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0801 - accuracy: 0.9799 - val_loss: 4.4346 - val_accuracy: 0.6994\n",
            "Epoch 122/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0802 - accuracy: 0.9811 - val_loss: 4.6070 - val_accuracy: 0.7036\n",
            "Epoch 123/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0733 - accuracy: 0.9818 - val_loss: 4.6944 - val_accuracy: 0.7000\n",
            "Epoch 124/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0870 - accuracy: 0.9795 - val_loss: 4.7929 - val_accuracy: 0.6953\n",
            "Epoch 125/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0792 - accuracy: 0.9816 - val_loss: 4.6086 - val_accuracy: 0.6966\n",
            "Epoch 126/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0817 - accuracy: 0.9811 - val_loss: 4.9106 - val_accuracy: 0.6818\n",
            "Epoch 127/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0713 - accuracy: 0.9823 - val_loss: 5.0472 - val_accuracy: 0.6878\n",
            "Epoch 128/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0870 - accuracy: 0.9802 - val_loss: 4.8864 - val_accuracy: 0.6940\n",
            "Epoch 129/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0795 - accuracy: 0.9815 - val_loss: 4.9349 - val_accuracy: 0.6989\n",
            "Epoch 130/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0821 - accuracy: 0.9808 - val_loss: 4.9689 - val_accuracy: 0.6955\n",
            "Epoch 131/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0783 - accuracy: 0.9812 - val_loss: 4.8659 - val_accuracy: 0.6955\n",
            "Epoch 132/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0769 - accuracy: 0.9821 - val_loss: 5.1558 - val_accuracy: 0.6939\n",
            "Epoch 133/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0823 - accuracy: 0.9810 - val_loss: 4.9458 - val_accuracy: 0.6979\n",
            "Epoch 134/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0785 - accuracy: 0.9823 - val_loss: 5.1337 - val_accuracy: 0.6964\n",
            "Epoch 135/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0891 - accuracy: 0.9801 - val_loss: 5.0547 - val_accuracy: 0.6901\n",
            "Epoch 136/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0789 - accuracy: 0.9819 - val_loss: 4.9674 - val_accuracy: 0.6963\n",
            "Epoch 137/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0818 - accuracy: 0.9812 - val_loss: 5.0047 - val_accuracy: 0.6947\n",
            "Epoch 138/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0897 - accuracy: 0.9796 - val_loss: 5.0054 - val_accuracy: 0.6983\n",
            "Epoch 139/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0748 - accuracy: 0.9830 - val_loss: 5.3369 - val_accuracy: 0.7008\n",
            "Epoch 140/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0878 - accuracy: 0.9807 - val_loss: 5.3321 - val_accuracy: 0.6914\n",
            "Epoch 141/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0862 - accuracy: 0.9809 - val_loss: 5.1260 - val_accuracy: 0.7007\n",
            "Epoch 142/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0856 - accuracy: 0.9810 - val_loss: 5.1724 - val_accuracy: 0.6953\n",
            "Epoch 143/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0745 - accuracy: 0.9838 - val_loss: 5.3777 - val_accuracy: 0.6926\n",
            "Epoch 144/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0852 - accuracy: 0.9808 - val_loss: 5.2757 - val_accuracy: 0.7038\n",
            "Epoch 145/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0722 - accuracy: 0.9846 - val_loss: 5.2527 - val_accuracy: 0.7012\n",
            "Epoch 146/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1010 - accuracy: 0.9787 - val_loss: 5.1470 - val_accuracy: 0.7013\n",
            "Epoch 147/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0706 - accuracy: 0.9846 - val_loss: 5.3923 - val_accuracy: 0.6936\n",
            "Epoch 148/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0893 - accuracy: 0.9812 - val_loss: 5.5004 - val_accuracy: 0.6999\n",
            "Epoch 149/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0860 - accuracy: 0.9827 - val_loss: 5.6120 - val_accuracy: 0.6920\n",
            "Epoch 150/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0843 - accuracy: 0.9816 - val_loss: 5.5327 - val_accuracy: 0.6957\n",
            "Epoch 151/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0787 - accuracy: 0.9821 - val_loss: 5.8236 - val_accuracy: 0.6917\n",
            "Epoch 152/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0865 - accuracy: 0.9819 - val_loss: 5.3897 - val_accuracy: 0.6973\n",
            "Epoch 153/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0888 - accuracy: 0.9818 - val_loss: 5.5000 - val_accuracy: 0.6938\n",
            "Epoch 154/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0868 - accuracy: 0.9818 - val_loss: 5.7389 - val_accuracy: 0.6944\n",
            "Epoch 155/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0744 - accuracy: 0.9845 - val_loss: 6.0186 - val_accuracy: 0.6995\n",
            "Epoch 156/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0839 - accuracy: 0.9826 - val_loss: 5.8239 - val_accuracy: 0.6947\n",
            "Epoch 157/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0893 - accuracy: 0.9821 - val_loss: 5.6630 - val_accuracy: 0.6954\n",
            "Epoch 158/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0951 - accuracy: 0.9802 - val_loss: 5.8269 - val_accuracy: 0.6956\n",
            "Epoch 159/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0756 - accuracy: 0.9833 - val_loss: 5.9930 - val_accuracy: 0.6928\n",
            "Epoch 160/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0819 - accuracy: 0.9821 - val_loss: 5.7221 - val_accuracy: 0.6990\n",
            "Epoch 161/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0817 - accuracy: 0.9824 - val_loss: 5.8277 - val_accuracy: 0.6984\n",
            "Epoch 162/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0781 - accuracy: 0.9836 - val_loss: 6.0848 - val_accuracy: 0.6949\n",
            "Epoch 163/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0935 - accuracy: 0.9808 - val_loss: 5.7202 - val_accuracy: 0.6930\n",
            "Epoch 164/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0757 - accuracy: 0.9835 - val_loss: 5.8723 - val_accuracy: 0.6966\n",
            "Epoch 165/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0836 - accuracy: 0.9831 - val_loss: 6.1256 - val_accuracy: 0.6969\n",
            "Epoch 166/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0868 - accuracy: 0.9823 - val_loss: 5.9589 - val_accuracy: 0.6966\n",
            "Epoch 167/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0827 - accuracy: 0.9830 - val_loss: 5.9652 - val_accuracy: 0.6991\n",
            "Epoch 168/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0815 - accuracy: 0.9825 - val_loss: 6.0027 - val_accuracy: 0.6934\n",
            "Epoch 169/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0841 - accuracy: 0.9836 - val_loss: 6.0787 - val_accuracy: 0.7004\n",
            "Epoch 170/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0889 - accuracy: 0.9825 - val_loss: 6.2133 - val_accuracy: 0.6946\n",
            "Epoch 171/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0837 - accuracy: 0.9829 - val_loss: 6.0873 - val_accuracy: 0.6919\n",
            "Epoch 172/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0730 - accuracy: 0.9846 - val_loss: 6.3765 - val_accuracy: 0.7021\n",
            "Epoch 173/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0928 - accuracy: 0.9818 - val_loss: 6.2363 - val_accuracy: 0.6948\n",
            "Epoch 174/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0801 - accuracy: 0.9839 - val_loss: 6.4670 - val_accuracy: 0.6935\n",
            "Epoch 175/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0856 - accuracy: 0.9836 - val_loss: 6.4825 - val_accuracy: 0.6959\n",
            "Epoch 176/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0964 - accuracy: 0.9818 - val_loss: 6.2464 - val_accuracy: 0.6926\n",
            "Epoch 177/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0754 - accuracy: 0.9853 - val_loss: 6.3934 - val_accuracy: 0.6999\n",
            "Epoch 178/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0841 - accuracy: 0.9838 - val_loss: 6.4992 - val_accuracy: 0.6998\n",
            "Epoch 179/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0875 - accuracy: 0.9829 - val_loss: 6.7595 - val_accuracy: 0.6917\n",
            "Epoch 180/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0905 - accuracy: 0.9836 - val_loss: 6.5977 - val_accuracy: 0.6948\n",
            "Epoch 181/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0894 - accuracy: 0.9834 - val_loss: 6.3786 - val_accuracy: 0.6885\n",
            "Epoch 182/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0896 - accuracy: 0.9828 - val_loss: 6.4822 - val_accuracy: 0.6974\n",
            "Epoch 183/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0842 - accuracy: 0.9835 - val_loss: 6.6444 - val_accuracy: 0.6982\n",
            "Epoch 184/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0841 - accuracy: 0.9835 - val_loss: 6.6516 - val_accuracy: 0.6843\n",
            "Epoch 185/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0883 - accuracy: 0.9831 - val_loss: 6.6911 - val_accuracy: 0.6948\n",
            "Epoch 186/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0911 - accuracy: 0.9833 - val_loss: 6.8711 - val_accuracy: 0.7003\n",
            "Epoch 187/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0827 - accuracy: 0.9838 - val_loss: 6.7656 - val_accuracy: 0.6977\n",
            "Epoch 188/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0870 - accuracy: 0.9840 - val_loss: 6.9200 - val_accuracy: 0.6988\n",
            "Epoch 189/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0895 - accuracy: 0.9843 - val_loss: 6.7281 - val_accuracy: 0.6886\n",
            "Epoch 190/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0768 - accuracy: 0.9845 - val_loss: 7.0376 - val_accuracy: 0.6982\n",
            "Epoch 191/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0866 - accuracy: 0.9855 - val_loss: 6.7988 - val_accuracy: 0.6975\n",
            "Epoch 192/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0881 - accuracy: 0.9832 - val_loss: 7.1656 - val_accuracy: 0.6982\n",
            "Epoch 193/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0828 - accuracy: 0.9850 - val_loss: 6.7887 - val_accuracy: 0.6951\n",
            "Epoch 194/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0861 - accuracy: 0.9844 - val_loss: 7.0969 - val_accuracy: 0.6988\n",
            "Epoch 195/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0959 - accuracy: 0.9835 - val_loss: 6.8837 - val_accuracy: 0.6927\n",
            "Epoch 196/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0861 - accuracy: 0.9847 - val_loss: 7.0456 - val_accuracy: 0.6952\n",
            "Epoch 197/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0820 - accuracy: 0.9847 - val_loss: 7.1601 - val_accuracy: 0.6974\n",
            "Epoch 198/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0850 - accuracy: 0.9856 - val_loss: 7.3451 - val_accuracy: 0.7047\n",
            "Epoch 199/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0946 - accuracy: 0.9840 - val_loss: 7.3300 - val_accuracy: 0.7025\n",
            "Epoch 200/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0808 - accuracy: 0.9851 - val_loss: 6.8557 - val_accuracy: 0.6977\n",
            "Epoch 201/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0907 - accuracy: 0.9842 - val_loss: 7.4304 - val_accuracy: 0.6978\n",
            "Epoch 202/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1019 - accuracy: 0.9828 - val_loss: 7.2083 - val_accuracy: 0.6928\n",
            "Epoch 203/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0867 - accuracy: 0.9850 - val_loss: 7.6461 - val_accuracy: 0.6932\n",
            "Epoch 204/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0878 - accuracy: 0.9855 - val_loss: 7.6719 - val_accuracy: 0.6909\n",
            "Epoch 205/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0996 - accuracy: 0.9838 - val_loss: 7.6459 - val_accuracy: 0.6982\n",
            "Epoch 206/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0898 - accuracy: 0.9852 - val_loss: 7.5424 - val_accuracy: 0.6974\n",
            "Epoch 207/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0938 - accuracy: 0.9833 - val_loss: 7.5415 - val_accuracy: 0.6973\n",
            "Epoch 208/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0875 - accuracy: 0.9854 - val_loss: 7.5211 - val_accuracy: 0.6911\n",
            "Epoch 209/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0873 - accuracy: 0.9853 - val_loss: 7.7415 - val_accuracy: 0.6932\n",
            "Epoch 210/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0946 - accuracy: 0.9846 - val_loss: 7.7487 - val_accuracy: 0.6903\n",
            "Epoch 211/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0950 - accuracy: 0.9844 - val_loss: 7.7390 - val_accuracy: 0.6950\n",
            "Epoch 212/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0847 - accuracy: 0.9855 - val_loss: 7.5665 - val_accuracy: 0.6929\n",
            "Epoch 213/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0999 - accuracy: 0.9833 - val_loss: 7.9662 - val_accuracy: 0.6894\n",
            "Epoch 214/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0942 - accuracy: 0.9850 - val_loss: 7.8274 - val_accuracy: 0.6969\n",
            "Epoch 215/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0831 - accuracy: 0.9858 - val_loss: 8.1273 - val_accuracy: 0.6974\n",
            "Epoch 216/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1034 - accuracy: 0.9837 - val_loss: 8.0760 - val_accuracy: 0.6968\n",
            "Epoch 217/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0901 - accuracy: 0.9857 - val_loss: 7.8235 - val_accuracy: 0.7025\n",
            "Epoch 218/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0882 - accuracy: 0.9860 - val_loss: 8.1848 - val_accuracy: 0.6988\n",
            "Epoch 219/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0926 - accuracy: 0.9846 - val_loss: 8.3263 - val_accuracy: 0.6933\n",
            "Epoch 220/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0988 - accuracy: 0.9846 - val_loss: 8.0262 - val_accuracy: 0.6976\n",
            "Epoch 221/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0853 - accuracy: 0.9858 - val_loss: 8.2565 - val_accuracy: 0.6957\n",
            "Epoch 222/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0923 - accuracy: 0.9850 - val_loss: 8.4510 - val_accuracy: 0.6921\n",
            "Epoch 223/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0916 - accuracy: 0.9851 - val_loss: 8.1443 - val_accuracy: 0.7003\n",
            "Epoch 224/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0954 - accuracy: 0.9848 - val_loss: 8.4019 - val_accuracy: 0.6959\n",
            "Epoch 225/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0957 - accuracy: 0.9844 - val_loss: 8.4605 - val_accuracy: 0.6971\n",
            "Epoch 226/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0890 - accuracy: 0.9852 - val_loss: 8.0019 - val_accuracy: 0.6951\n",
            "Epoch 227/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0942 - accuracy: 0.9852 - val_loss: 8.3822 - val_accuracy: 0.6909\n",
            "Epoch 228/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1008 - accuracy: 0.9849 - val_loss: 8.6611 - val_accuracy: 0.6976\n",
            "Epoch 229/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1025 - accuracy: 0.9846 - val_loss: 8.3068 - val_accuracy: 0.6985\n",
            "Epoch 230/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0873 - accuracy: 0.9868 - val_loss: 8.7069 - val_accuracy: 0.6996\n",
            "Epoch 231/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0944 - accuracy: 0.9859 - val_loss: 9.1374 - val_accuracy: 0.6846\n",
            "Epoch 232/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1026 - accuracy: 0.9846 - val_loss: 8.7946 - val_accuracy: 0.6941\n",
            "Epoch 233/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0892 - accuracy: 0.9861 - val_loss: 8.7673 - val_accuracy: 0.6962\n",
            "Epoch 234/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0807 - accuracy: 0.9875 - val_loss: 8.6917 - val_accuracy: 0.6972\n",
            "Epoch 235/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1140 - accuracy: 0.9837 - val_loss: 8.9319 - val_accuracy: 0.6960\n",
            "Epoch 236/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1013 - accuracy: 0.9850 - val_loss: 9.1213 - val_accuracy: 0.6918\n",
            "Epoch 237/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1039 - accuracy: 0.9851 - val_loss: 8.9316 - val_accuracy: 0.7010\n",
            "Epoch 238/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0971 - accuracy: 0.9858 - val_loss: 9.0804 - val_accuracy: 0.7002\n",
            "Epoch 239/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0912 - accuracy: 0.9864 - val_loss: 9.2471 - val_accuracy: 0.7002\n",
            "Epoch 240/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1032 - accuracy: 0.9849 - val_loss: 9.6571 - val_accuracy: 0.6780\n",
            "Epoch 241/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1007 - accuracy: 0.9848 - val_loss: 9.2171 - val_accuracy: 0.6968\n",
            "Epoch 242/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0914 - accuracy: 0.9861 - val_loss: 9.1889 - val_accuracy: 0.6925\n",
            "Epoch 243/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0899 - accuracy: 0.9870 - val_loss: 9.2238 - val_accuracy: 0.6910\n",
            "Epoch 244/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1004 - accuracy: 0.9854 - val_loss: 9.5323 - val_accuracy: 0.6943\n",
            "Epoch 245/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1065 - accuracy: 0.9853 - val_loss: 9.3989 - val_accuracy: 0.6866\n",
            "Epoch 246/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0856 - accuracy: 0.9871 - val_loss: 9.3084 - val_accuracy: 0.6924\n",
            "Epoch 247/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1045 - accuracy: 0.9861 - val_loss: 10.1403 - val_accuracy: 0.6829\n",
            "Epoch 248/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1050 - accuracy: 0.9850 - val_loss: 9.3398 - val_accuracy: 0.6945\n",
            "Epoch 249/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0924 - accuracy: 0.9862 - val_loss: 9.5195 - val_accuracy: 0.6975\n",
            "Epoch 250/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1000 - accuracy: 0.9857 - val_loss: 9.4480 - val_accuracy: 0.6900\n",
            "Epoch 251/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1088 - accuracy: 0.9855 - val_loss: 9.2912 - val_accuracy: 0.6937\n",
            "Epoch 252/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1000 - accuracy: 0.9858 - val_loss: 9.8541 - val_accuracy: 0.6919\n",
            "Epoch 253/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1018 - accuracy: 0.9859 - val_loss: 10.0738 - val_accuracy: 0.6920\n",
            "Epoch 254/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0784 - accuracy: 0.9882 - val_loss: 9.9155 - val_accuracy: 0.6953\n",
            "Epoch 255/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1137 - accuracy: 0.9852 - val_loss: 9.7019 - val_accuracy: 0.6974\n",
            "Epoch 256/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0956 - accuracy: 0.9866 - val_loss: 9.6800 - val_accuracy: 0.6944\n",
            "Epoch 257/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0935 - accuracy: 0.9866 - val_loss: 10.0176 - val_accuracy: 0.7009\n",
            "Epoch 258/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0939 - accuracy: 0.9871 - val_loss: 9.5791 - val_accuracy: 0.6988\n",
            "Epoch 259/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1218 - accuracy: 0.9845 - val_loss: 9.9839 - val_accuracy: 0.6950\n",
            "Epoch 260/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0825 - accuracy: 0.9880 - val_loss: 9.3862 - val_accuracy: 0.6993\n",
            "Epoch 261/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1071 - accuracy: 0.9857 - val_loss: 10.6218 - val_accuracy: 0.6969\n",
            "Epoch 262/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0970 - accuracy: 0.9874 - val_loss: 10.5159 - val_accuracy: 0.6860\n",
            "Epoch 263/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1046 - accuracy: 0.9861 - val_loss: 10.3737 - val_accuracy: 0.6936\n",
            "Epoch 264/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1072 - accuracy: 0.9859 - val_loss: 10.1564 - val_accuracy: 0.6911\n",
            "Epoch 265/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0906 - accuracy: 0.9885 - val_loss: 10.3667 - val_accuracy: 0.6934\n",
            "Epoch 266/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1107 - accuracy: 0.9855 - val_loss: 10.7397 - val_accuracy: 0.6912\n",
            "Epoch 267/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1079 - accuracy: 0.9857 - val_loss: 10.6248 - val_accuracy: 0.7005\n",
            "Epoch 268/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1178 - accuracy: 0.9851 - val_loss: 11.2291 - val_accuracy: 0.6809\n",
            "Epoch 269/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1006 - accuracy: 0.9870 - val_loss: 9.9848 - val_accuracy: 0.6959\n",
            "Epoch 270/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0982 - accuracy: 0.9868 - val_loss: 10.6327 - val_accuracy: 0.6952\n",
            "Epoch 271/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1169 - accuracy: 0.9861 - val_loss: 10.7564 - val_accuracy: 0.6952\n",
            "Epoch 272/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1016 - accuracy: 0.9868 - val_loss: 10.8137 - val_accuracy: 0.6889\n",
            "Epoch 273/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1050 - accuracy: 0.9861 - val_loss: 10.8217 - val_accuracy: 0.6957\n",
            "Epoch 274/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1047 - accuracy: 0.9869 - val_loss: 10.9185 - val_accuracy: 0.6954\n",
            "Epoch 275/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1172 - accuracy: 0.9860 - val_loss: 10.8353 - val_accuracy: 0.6981\n",
            "Epoch 276/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1020 - accuracy: 0.9874 - val_loss: 10.8064 - val_accuracy: 0.6986\n",
            "Epoch 277/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1091 - accuracy: 0.9869 - val_loss: 10.8961 - val_accuracy: 0.6963\n",
            "Epoch 278/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1086 - accuracy: 0.9868 - val_loss: 10.8090 - val_accuracy: 0.6925\n",
            "Epoch 279/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1044 - accuracy: 0.9879 - val_loss: 11.3781 - val_accuracy: 0.6970\n",
            "Epoch 280/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1010 - accuracy: 0.9870 - val_loss: 10.7173 - val_accuracy: 0.7009\n",
            "Epoch 281/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1139 - accuracy: 0.9867 - val_loss: 11.1728 - val_accuracy: 0.6981\n",
            "Epoch 282/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1032 - accuracy: 0.9865 - val_loss: 11.4420 - val_accuracy: 0.6992\n",
            "Epoch 283/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1157 - accuracy: 0.9868 - val_loss: 11.6093 - val_accuracy: 0.6955\n",
            "Epoch 284/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1061 - accuracy: 0.9876 - val_loss: 11.4106 - val_accuracy: 0.7009\n",
            "Epoch 285/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1124 - accuracy: 0.9864 - val_loss: 12.1500 - val_accuracy: 0.6965\n",
            "Epoch 286/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1125 - accuracy: 0.9874 - val_loss: 11.7494 - val_accuracy: 0.6946\n",
            "Epoch 287/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1206 - accuracy: 0.9872 - val_loss: 11.7920 - val_accuracy: 0.6965\n",
            "Epoch 288/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1018 - accuracy: 0.9879 - val_loss: 11.6519 - val_accuracy: 0.6950\n",
            "Epoch 289/300\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1070 - accuracy: 0.9870 - val_loss: 12.0469 - val_accuracy: 0.6884\n",
            "Epoch 290/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1160 - accuracy: 0.9869 - val_loss: 11.9651 - val_accuracy: 0.6875\n",
            "Epoch 291/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1085 - accuracy: 0.9879 - val_loss: 12.0527 - val_accuracy: 0.6970\n",
            "Epoch 292/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1047 - accuracy: 0.9871 - val_loss: 12.5500 - val_accuracy: 0.6843\n",
            "Epoch 293/300\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1086 - accuracy: 0.9874 - val_loss: 12.2519 - val_accuracy: 0.6962\n",
            "Epoch 294/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1074 - accuracy: 0.9877 - val_loss: 12.7588 - val_accuracy: 0.6966\n",
            "Epoch 295/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1259 - accuracy: 0.9870 - val_loss: 12.6645 - val_accuracy: 0.6838\n",
            "Epoch 296/300\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0997 - accuracy: 0.9880 - val_loss: 12.4090 - val_accuracy: 0.6906\n",
            "Epoch 297/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1016 - accuracy: 0.9874 - val_loss: 13.0629 - val_accuracy: 0.6880\n",
            "Epoch 298/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1281 - accuracy: 0.9864 - val_loss: 12.5684 - val_accuracy: 0.6958\n",
            "Epoch 299/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0994 - accuracy: 0.9884 - val_loss: 13.9220 - val_accuracy: 0.6825\n",
            "Epoch 300/300\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1101 - accuracy: 0.9875 - val_loss: 12.4319 - val_accuracy: 0.6969\n",
            "Extended Model Training Time: 2665.5652663707733 seconds\n",
            "Extended Model Training Loss: 0.11014129221439362\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 12.4319 - accuracy: 0.6969\n",
            "Extended Model Evaluation Accuracy: 0.6969000101089478\n"
          ]
        }
      ],
      "source": [
        "#1b\n",
        "model_extended = models.Sequential()\n",
        "model_extended.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model_extended.add(layers.MaxPooling2D((2, 2)))\n",
        "model_extended.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model_extended.add(layers.MaxPooling2D((2, 2)))\n",
        "model_extended.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model_extended.add(layers.MaxPooling2D((2, 2)))\n",
        "model_extended.add(layers.Flatten())\n",
        "model_extended.add(layers.Dense(256, activation='relu'))\n",
        "model_extended.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model_extended.compile(optimizer='adam',\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "start_time_extended = time.time()\n",
        "history_extended = model_extended.fit(train_images, train_labels, epochs=300, validation_data=(test_images, test_labels))\n",
        "end_time_extended = time.time()\n",
        "\n",
        "print(f\"Extended Model Training Time: {end_time_extended - start_time_extended} seconds\")\n",
        "print(f\"Extended Model Training Loss: {history_extended.history['loss'][-1]}\")\n",
        "print(f\"Extended Model Evaluation Accuracy: {model_extended.evaluate(test_images, test_labels)[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RAH-H6o3XJr",
        "outputId": "7574b4d8-418d-454e-a2da-e8a206ca837c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170498071/170498071 [00:10<00:00, 16341414.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Epoch 1/300, Loss: 1.59210804203892\n",
            "Epoch 2/300, Loss: 1.21388302061259\n",
            "Epoch 3/300, Loss: 1.0595552994467108\n",
            "Epoch 4/300, Loss: 0.964470315162483\n",
            "Epoch 5/300, Loss: 0.9035164424982827\n",
            "Epoch 6/300, Loss: 0.8421143467926309\n",
            "Epoch 7/300, Loss: 0.804350350366529\n",
            "Epoch 8/300, Loss: 0.7669548871343398\n",
            "Epoch 9/300, Loss: 0.7314508683083917\n",
            "Epoch 10/300, Loss: 0.7036980501068827\n",
            "Epoch 11/300, Loss: 0.6810534130734252\n",
            "Epoch 12/300, Loss: 0.6589728748935568\n",
            "Epoch 13/300, Loss: 0.6407483408365713\n",
            "Epoch 14/300, Loss: 0.6236408146293572\n",
            "Epoch 15/300, Loss: 0.6128356570325544\n",
            "Epoch 16/300, Loss: 0.5953512428437963\n",
            "Epoch 17/300, Loss: 0.5817578385591202\n",
            "Epoch 18/300, Loss: 0.5687048468748321\n",
            "Epoch 19/300, Loss: 0.5636324975115564\n",
            "Epoch 20/300, Loss: 0.5534984634622283\n",
            "Epoch 21/300, Loss: 0.5390841603812659\n",
            "Epoch 22/300, Loss: 0.5343528678045248\n",
            "Epoch 23/300, Loss: 0.52148441737875\n",
            "Epoch 24/300, Loss: 0.5154637404338783\n",
            "Epoch 25/300, Loss: 0.5084638459336422\n",
            "Epoch 26/300, Loss: 0.5061082296511706\n",
            "Epoch 27/300, Loss: 0.49796757079146403\n",
            "Epoch 28/300, Loss: 0.49219368201921054\n",
            "Epoch 29/300, Loss: 0.48397458746762534\n",
            "Epoch 30/300, Loss: 0.4809659616759671\n",
            "Epoch 31/300, Loss: 0.47929764327490726\n",
            "Epoch 32/300, Loss: 0.47425613683812756\n",
            "Epoch 33/300, Loss: 0.46511896358579013\n",
            "Epoch 34/300, Loss: 0.46280366363351605\n",
            "Epoch 35/300, Loss: 0.45498153889346915\n",
            "Epoch 36/300, Loss: 0.45307584773853915\n",
            "Epoch 37/300, Loss: 0.4533291330079898\n",
            "Epoch 38/300, Loss: 0.44379493523665403\n",
            "Epoch 39/300, Loss: 0.441304511731238\n",
            "Epoch 40/300, Loss: 0.43969479955904317\n",
            "Epoch 41/300, Loss: 0.438423911952759\n",
            "Epoch 42/300, Loss: 0.43284450124596696\n",
            "Epoch 43/300, Loss: 0.43170911212787605\n",
            "Epoch 44/300, Loss: 0.4279877778399936\n",
            "Epoch 45/300, Loss: 0.4256209636016575\n",
            "Epoch 46/300, Loss: 0.41685376163867427\n",
            "Epoch 47/300, Loss: 0.42023862768774445\n",
            "Epoch 48/300, Loss: 0.4138728233478258\n",
            "Epoch 49/300, Loss: 0.4146237172319761\n",
            "Epoch 50/300, Loss: 0.41393747893364535\n",
            "Epoch 51/300, Loss: 0.4107184294049087\n",
            "Epoch 52/300, Loss: 0.40831187028256827\n",
            "Epoch 53/300, Loss: 0.40211271675651333\n",
            "Epoch 54/300, Loss: 0.40233123452995745\n",
            "Epoch 55/300, Loss: 0.3983740039608058\n",
            "Epoch 56/300, Loss: 0.39295056906273906\n",
            "Epoch 57/300, Loss: 0.3951022768455088\n",
            "Epoch 58/300, Loss: 0.391520606187146\n",
            "Epoch 59/300, Loss: 0.3938842723551004\n",
            "Epoch 60/300, Loss: 0.3877565967838478\n",
            "Epoch 61/300, Loss: 0.38445119893230745\n",
            "Epoch 62/300, Loss: 0.3840142358142092\n",
            "Epoch 63/300, Loss: 0.3873633878577091\n",
            "Epoch 64/300, Loss: 0.3798848163631871\n",
            "Epoch 65/300, Loss: 0.3843915093013698\n",
            "Epoch 66/300, Loss: 0.3771341204776636\n",
            "Epoch 67/300, Loss: 0.37745868538499183\n",
            "Epoch 68/300, Loss: 0.3767578270086242\n",
            "Epoch 69/300, Loss: 0.37458301223147555\n",
            "Epoch 70/300, Loss: 0.36949638593608464\n",
            "Epoch 71/300, Loss: 0.36866235397660824\n",
            "Epoch 72/300, Loss: 0.3739873863508939\n",
            "Epoch 73/300, Loss: 0.3719466972305342\n",
            "Epoch 74/300, Loss: 0.3699869793051344\n",
            "Epoch 75/300, Loss: 0.3669640911776391\n",
            "Epoch 76/300, Loss: 0.3665900118172626\n",
            "Epoch 77/300, Loss: 0.35829702482732667\n",
            "Epoch 78/300, Loss: 0.36181751747265495\n",
            "Epoch 79/300, Loss: 0.3640142026574106\n",
            "Epoch 80/300, Loss: 0.3540556402996068\n",
            "Epoch 81/300, Loss: 0.35403463610297886\n",
            "Epoch 82/300, Loss: 0.35753037286993794\n",
            "Epoch 83/300, Loss: 0.3541774929065229\n",
            "Epoch 84/300, Loss: 0.3539096695154219\n",
            "Epoch 85/300, Loss: 0.3496608400474424\n",
            "Epoch 86/300, Loss: 0.3504823940374967\n",
            "Epoch 87/300, Loss: 0.35190609584340965\n",
            "Epoch 88/300, Loss: 0.3515951347625469\n",
            "Epoch 89/300, Loss: 0.3486116123778741\n",
            "Epoch 90/300, Loss: 0.34586702731183117\n",
            "Epoch 91/300, Loss: 0.3503170499716268\n",
            "Epoch 92/300, Loss: 0.3460920612754114\n",
            "Epoch 93/300, Loss: 0.3467217741910454\n",
            "Epoch 94/300, Loss: 0.3420546320469483\n",
            "Epoch 95/300, Loss: 0.3391891764977094\n",
            "Epoch 96/300, Loss: 0.3399372471358313\n",
            "Epoch 97/300, Loss: 0.34201270203723017\n",
            "Epoch 98/300, Loss: 0.33979785621471115\n",
            "Epoch 99/300, Loss: 0.341003464339563\n",
            "Epoch 100/300, Loss: 0.3384663076961742\n",
            "Epoch 101/300, Loss: 0.3391933302345026\n",
            "Epoch 102/300, Loss: 0.3325598725425008\n",
            "Epoch 103/300, Loss: 0.3373719736304887\n",
            "Epoch 104/300, Loss: 0.3334116272037596\n",
            "Epoch 105/300, Loss: 0.3367921448005435\n",
            "Epoch 106/300, Loss: 0.33399996528273346\n",
            "Epoch 107/300, Loss: 0.3330800277955087\n",
            "Epoch 108/300, Loss: 0.3270935724725199\n",
            "Epoch 109/300, Loss: 0.3362003644866407\n",
            "Epoch 110/300, Loss: 0.33099918379960463\n",
            "Epoch 111/300, Loss: 0.3307404081191858\n",
            "Epoch 112/300, Loss: 0.325965512277144\n",
            "Epoch 113/300, Loss: 0.326181507438345\n",
            "Epoch 114/300, Loss: 0.3314337397322935\n",
            "Epoch 115/300, Loss: 0.3271089070821967\n",
            "Epoch 116/300, Loss: 0.3249332392326249\n",
            "Epoch 117/300, Loss: 0.32600041233060306\n",
            "Epoch 118/300, Loss: 0.32407358486938964\n",
            "Epoch 119/300, Loss: 0.32385096589432044\n",
            "Epoch 120/300, Loss: 0.3237635689737547\n",
            "Epoch 121/300, Loss: 0.3245521397579966\n",
            "Epoch 122/300, Loss: 0.32054176269208684\n",
            "Epoch 123/300, Loss: 0.3233289118865719\n",
            "Epoch 124/300, Loss: 0.3207480387900339\n",
            "Epoch 125/300, Loss: 0.3198474719739326\n",
            "Epoch 126/300, Loss: 0.31989332611489174\n",
            "Epoch 127/300, Loss: 0.32124841338990595\n",
            "Epoch 128/300, Loss: 0.3172915379333374\n",
            "Epoch 129/300, Loss: 0.3191733610104112\n",
            "Epoch 130/300, Loss: 0.3155155695517502\n",
            "Epoch 131/300, Loss: 0.31659082270910976\n",
            "Epoch 132/300, Loss: 0.31886804577372874\n",
            "Epoch 133/300, Loss: 0.315387949442772\n",
            "Epoch 134/300, Loss: 0.3128338967690535\n",
            "Epoch 135/300, Loss: 0.31152353865449384\n",
            "Epoch 136/300, Loss: 0.31693834539912547\n",
            "Epoch 137/300, Loss: 0.31702821311133594\n"
          ]
        }
      ],
      "source": [
        "#2\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet10(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet10, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self.make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self.make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "def train(model, criterion, optimizer, epochs):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    criterion.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "def test(model):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Accuracy on test set: {accuracy * 100:.2f}%\")\n",
        "\n",
        "resnet10 = ResNet10(ResNetBlock, [1, 1, 1])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet10.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "train(resnet10, criterion, optimizer, epochs=300)\n",
        "test(resnet10)\n",
        "\n",
        "resnet10_weight_decay = ResNet10(ResNetBlock, [1, 1, 1])\n",
        "optimizer_weight_decay = optim.SGD(resnet10_weight_decay.parameters(), lr=0.01, momentum=0.9, weight_decay=0.001)\n",
        "\n",
        "train(resnet10_weight_decay, criterion, optimizer_weight_decay, epochs=300)\n",
        "test(resnet10_weight_decay)\n",
        "\n",
        "resnet10_dropout = ResNet10(ResNetBlock, [1, 1, 1])\n",
        "resnet10_dropout.fc = nn.Sequential(\n",
        "    nn.Linear(64, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.Linear(256, 10)\n",
        ")\n",
        "optimizer_dropout = optim.SGD(resnet10_dropout.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "train(resnet10_dropout, criterion, optimizer_dropout, epochs=300)\n",
        "test(resnet10_dropout)\n",
        "\n",
        "resnet10_bn = ResNet10(ResNetBlock, [1, 1, 1])\n",
        "resnet10_bn.fc = nn.Sequential(\n",
        "    nn.Linear(64, 256),\n",
        "    nn.BatchNorm1d(256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 10)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkwcZevnWnZKV8xbYYCJh9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}